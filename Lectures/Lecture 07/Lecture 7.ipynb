{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 7 - Maximum Likelihood Estimation (MLE), Maximum A Posteriori (MAP) & Conjugate Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation (MLE) & Maximum A Posteriori (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:blue\">Maximum Likelihood Estimation (MLE)</span></h2>\n",
    "<center>(Frequentist approach)</center>\n",
    "\n",
    "In **Maximum Likelihood Estimation** (also referred to as **MLE**) we want to *find the set of parameters* that **maximize** the data likelihood $P(\\mathbf{t}|\\mathbf{y}(\\mathbf{x};\\mathbf{w}))$. We want to find the *optimal* set of parameters under some assumed distribution such that the data is most likely.\n",
    "\n",
    "* MLE focuses on maximizing the data likelihood, which *usually* provides a pretty good estimate\n",
    "\n",
    "* A common trick to maximize the data likelihood is to maximize the log likelihood\n",
    "\n",
    "* MLE is purely data driven \n",
    "\n",
    "* MLE works best when we have lots and lots of data\n",
    "\n",
    "* MLE will likely overfit when we have small amounts of data or, at least, becomes unreliable\n",
    "\n",
    "* It estimates relative frequency for our model parameters. Therefore it needs incredibly large amounts of data (infinite!) to estimate the true likelihood parameters\n",
    "    * This is a problem when we want to make inferences and/or predictions outside the range of what the training data has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:orange\">Maximum A Posteriori (MAP)</span></h2>\n",
    "<center>(Bayesian approach)</center>\n",
    "\n",
    "In **Maximum A Posteriori** (also referred as **MAP**) we want to *find the set of parameters* that **maximize** the posterior probability $P(\\mathbf{w}|\\mathbf{t})$. We want to find the *optimal* set of parameters under some assumed distribution such that the parameters are most likely to have been drawn off of given some prior beliefs.\n",
    "\n",
    "* MAP focuses on maximizing the posterior probability - data  likelihood with a prior\n",
    "\n",
    "* A common trick to maximize the posterior probability is to maximize the log likelihood\n",
    "\n",
    "* MAP is data driven \n",
    "\n",
    "* MAP is mostly driven by the prior beliefs\n",
    "\n",
    "* MAP works great with small amounts of data *if* our prior was chosen well\n",
    "\n",
    "* We need to assume and select a distribution for our prior beliefs\n",
    "    * A wrong choice of prior distribution can impact negatively our model estimation\n",
    "    \n",
    "* When we have lots and lots of data, the data likelihood will take over and the posterior will depend less and less on the prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppose you flip a coin 3 times. Let $H_i$ be the event that we observe Heads on flip $i$. Consider the event $E=H_1\\cap H_2\\cap H_3$, i.e. all flips were Heads. What is the probability that the next flip is Heads?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From classical probability (frequentist), we look only at data to compute the probability of flipping Heads:\n",
    "\n",
    "\\begin{align*}\n",
    "P(H) = \\frac{\\text{No. of observed Heads}}{\\text{No. of flips}} = \\frac{3}{3} = 1\n",
    "\\end{align*}\n",
    "\n",
    "From Bayesian statistics, we use Bayesian inferencing: What is the **hidden state** in this problem?\n",
    "\n",
    "* Hidden state: what type of coin was use in the experiment\n",
    "* Let's assume that we think only two types of coins could have been used, one fair coin and one 2-headed coin. So, by the **Law of Total Probability**:\n",
    "\n",
    "\\begin{align*}\n",
    "P(H) = P(H|\\text{fair})P(\\text{fair}) + P(\\overline{H}|\\text{2-headed})P(\\text{2-headed})\n",
    "\\end{align*}\n",
    "\n",
    "Furthermore, we can test different hypothesis by checking which hypothesis has the largest posterior probability value, e.g. if $P(\\text{fair}|E) > P(\\text{2-headed}|E)$, then hypothesis \"fair\" is more likely and that is what we will use to make predictions.\n",
    "    \n",
    "Note that the events $H_i$ are **conditionally independent**, that is: $P(H_1\\cap H_2|\\text{fair}) = P(H_1|\\text{fair})P(H_2|\\text{fair})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE and MAP Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign heads to the numerical value 1 and tails to 0. The sample space is $S=\\{0,1\\}$. Let $X$ be the discrete random variable (R.V.) that describes the outcome of flipping a coin. Furthermore, let the probability of heads ($x=1$) be equal to some *unknown* value $\\mu$. The probability mass function (pmf) of this R.V. is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "p(x|\\mu) = \\begin{cases} \\mu & \\text{if } x=1 \\\\ 1-\\mu & \\text{if }x=0\\\\ 0 & \\text{otherwise}  \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "* This is the **Bernoulli** discrete R.V.. The mean and variance (1st and 2nd moment) of the Bernoulli distribution are: $E[x] = \\mu$ and $E[\\left(x- E[x]\\right)^2] = \\mu(1-\\mu)$.\n",
    "\n",
    "* So, for every outcome of the event $E$, we will model it using a Bernoulli distribution, and each outcome is pairwise **conditionally independent**. Therefore, we have the event $E$ contains i.i.d. outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood (MLE) Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity of calculation, let $E=x_1\\cap x_2\\cap \\dots\\cap x_N$, where $x_i=\\{0,1\\}$ (0 for Tails and 1 for Heads). Then, for an experiment with $N$ samples, we can write the **data likelihood** as:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\mathbf{x}|\\mu) &= P(x_1\\cap x_2\\cap \\dots\\cap x_N|\\mu) \\\\\n",
    "&= P(x_1|\\mu)P(x_2|\\mu)\\dots P(x_N|\\mu) \\\\\n",
    "&= \\prod_{n=1}^N p(x_n|\\mu) \\\\\n",
    "&= \\prod_{n=1}^N \\mu^{x_n} (1-\\mu)^{1-x_n}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are interested in finding the value of $\\mu$ given a set of samples $\\mathbf{x}=\\{x_i\\}_{i=1}^N$. \n",
    "\n",
    "To optimize the data likelihood, we can apply the natural logarithm function to simplify:\n",
    "\n",
    "\\begin{align*}\n",
    "arg_\\mathbf{\\mu} \\max P(\\mathbf{x}|\\mu) &= \\arg_\\mathbf{\\mu} \\max \\ln \\left( P(\\mathbf{x}|\\mu) \\right)\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L} &= \\ln \\left( P(\\mathbf{x}|\\mu) \\right) = \\sum_{n=1}^N \\left(x_n \\ln(\\mu) + (1-x_n)\\ln(1-\\mu)\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can take the derivative of this function with respect to (w.r.t.) $\\mu$ and equal it to zero:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mu} &= 0\\\\\n",
    "(1-\\mu)\\sum_{n=1}^N x_n - \\mu \\left(N - \\sum_{n=1}^N x_n\\right) &= 0 \\\\\n",
    "\\sum_{n=1}^N x_n - \\mu\\sum_{n=1}^N x_n - \\mu N + \\mu\\sum_{n=1}^N x_n &= 0 \\\\\n",
    "\\sum_{n=1}^N x_n - \\mu N &= 0 \\\\\n",
    "\\mu_{\\text{MLE}} &= \\frac{1}{N} \\sum_{n=1}^N x_n\n",
    "\\end{align*}\n",
    "\n",
    "As expected, the MLE estimation for the probability of seeing heads in the next coin flip is equal to the **relative frequency** of the outcome heads.\n",
    "\n",
    "* Suppose you flipped the coin only once, and saw Tails. The probability of flipping Heads according to MLE would be 0.\n",
    "\n",
    "* MLE is **purely data driven**! This is sufficient *when* we have lots and lots of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum A Posteriori (MAP) Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MAP estimation of $\\mu$, we are instead optimizing the posterior probability:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\arg_{\\mu} \\max P(\\mu|\\mathbf{x}) \\\\\n",
    "=& \\arg_{\\mu} \\max \\frac{P(\\mathbf{x}|\\mu) P(\\mu)}{P(\\mathbf{x})} \\\\\n",
    "\\propto & \\text{  } \\arg_{\\mu} \\max P(\\mathbf{x}|\\mu) P(\\mu), P(\\mathbf{x})\\text{ is some constant value} \n",
    "\\end{align*}\n",
    "\n",
    "We have defined the data likelihood $P(\\mathbf{x}|\\mu)$, we now need to choose a **prior distribution** $P(\\mu)$.\n",
    "\n",
    "* This prior distribution will *encode* any prior knowledge we have about the hidden sate of the problem, in this case, the type of coin that was used.\n",
    "\n",
    "Let's say our **prior distribution** is the Beta Distribution. The Beta Distribution takes the form:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Beta}(x|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}\n",
    "\\end{align*}\n",
    "\n",
    "where $\\Gamma(x) = (x-1)!$ and $\\alpha,\\beta>0$.\n",
    "\n",
    "The mean and variance of the Beta distribution are: $E[x] = \\frac{\\alpha}{\\alpha+\\beta}$ and $E[(x-E[x])^2] = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's see what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 20\n",
    "b = 2\n",
    "x = np.arange(0,1,0.0001)\n",
    "Beta = (math.gamma(a+b)/(math.gamma(a)*math.gamma(b)))*x**(a-1)*(1-x)**(b-1)\n",
    "\n",
    "plt.plot(x, Beta, label='Beta Distribution')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Probability of Heads\\n $\\mu$',fontsize=15)\n",
    "plt.ylabel('Prior Probability\\n $P(\\mu)$',fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Beta Distribution as out prior, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\mu|\\alpha,\\beta) &= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&\\propto \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let:\n",
    "* $m$ the number of heads\n",
    "* $l$ the number of tails\n",
    "* $N=m+l$ the total number of coin flips \n",
    "\n",
    "We can write our **posterior probability** as:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\mu|\\mathbf{x}) &= \\frac{P(\\mathbf{x}|\\mu)P(\\mu)}{P(\\mathbf{x})}\\\\\n",
    "&\\propto P(\\mathbf{x}|\\mu)P(\\mu)\\\\\n",
    "&= \\left(\\prod_{n=1}^N \\mu^{x_n} (1-\\mu)^{1-x_n}\\right) \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&= \\mu^m (1-\\mu)^l \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&= \\mu^{m+\\alpha-1} (1-\\mu)^{l+\\beta-1}\n",
    "\\end{align*}\n",
    "\n",
    "The posterior probability has the same shape as the data likelihood. \n",
    "\n",
    "This is a special case called **Conjugate Prior Relationship**, which happens when the posterior has the same form as the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now optimize our posterior probability, and we will apply the same trick:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L} &= \\ln P(\\mu|\\mathbf{x}) = (m+\\alpha-1)\\ln(\\mu) + (l+\\beta-1)\\ln(1-\\mu)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now *optimize* our posterior probability:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mu} = 0 \\iff & \\frac{m+\\alpha-1}{\\mu} + \\frac{l+\\beta-1}{1-\\mu} = 0\\\\\n",
    "\\mu_{\\text{MAP}} &= \\frac{m+\\alpha-1}{m + l + \\alpha + \\beta -2}\n",
    "\\end{align*}\n",
    "\n",
    "This is our estimation of the probability of heads using MAP!\n",
    "\n",
    "* Our estimation for the probability of heads, $\\mu$, is going to depend on $\\alpha$ and $\\beta$ introduced by the prior distribution. We saw that they control the level of certainty as well as the center value.\n",
    "\n",
    "* With only a few samples, the prior will play a bigger role in the decision, but eventually the data takes over the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate this example with code:\n",
    "\n",
    "We saw the example where our input dataset $\\{x_i\\}_{i=1}^N$ is binary, where $x_i=\\{0,1\\}, \\forall i$. \n",
    "\n",
    "For each data sample $x_i$, we modeled its data likelihood as the Bernoulli distribution with parameter $\\mu$, i.e.\n",
    "\n",
    "\\begin{align*}\n",
    "x_i \\sim \\text{Bernoulli}(\\mu)\n",
    "\\end{align*}\n",
    "\n",
    "Furthermore, we assume that each sample is independent of each other. Hence our dataset is a collection of i.i.d. samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "## Prior Probability\n",
    "a = 2\n",
    "b = 20\n",
    "Beta = stats.beta(a,b)\n",
    "x = np.linspace(0,1,1000)\n",
    "\n",
    "plt.plot(x, Beta.pdf(x), label='Beta Distribution')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Probability of Heads\\n $\\mu$',fontsize=15)\n",
    "plt.ylabel('Prior Density Function\\n $P(\\mu)$',fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "\n",
    "Nflips = 10\n",
    "\n",
    "Outcomes = []\n",
    "for i in range(Nflips):\n",
    "    Outcomes += [stats.bernoulli(trueMU).rvs(1)[0]]\n",
    "    print(Outcomes)\n",
    "    print('MLE (Frequentist, data-driven): Probability of Heads = ', np.sum(Outcomes)/len(Outcomes))\n",
    "    print('MAP (Bayesian, uses prior): Probability of Heads = ', (np.sum(Outcomes)+a-1)/(len(Outcomes)+a+b-2))\n",
    "    input('Press enter to flip the coin again...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True value of the unknown parameter\n",
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "\n",
    "# Prior Initial Parameters\n",
    "a=2 # alpha\n",
    "b=20 # beta\n",
    "# Plotting prior\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "Beta = stats.beta(a,b)\n",
    "x = np.linspace(0,1,1000)\n",
    "plt.plot(x, Beta.pdf(x), label='Beta Distribution')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Probability of Heads\\n $\\mu$',fontsize=15)\n",
    "plt.ylabel('Prior Density Function\\n $P(\\mu)$',fontsize=15);\n",
    "\n",
    "\n",
    "# Sampling Training Data\n",
    "Nflips = 100\n",
    "Outcomes = stats.bernoulli(trueMU).rvs(Nflips)\n",
    "\n",
    "# Computing MLE and MAP estimates as data is being collected\n",
    "mu_MLE = []\n",
    "mu_MAP = []\n",
    "for i in range(1,Nflips+1):\n",
    "    mu_MLE += [np.sum(Outcomes[:i])/len(Outcomes[:i])]\n",
    "    mu_MAP += [(np.sum(Outcomes[:i])+a-1)/(len(Outcomes[:i])+a+b-2)]\n",
    "\n",
    "# Plotting estimates\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1,Nflips+1), mu_MLE, '-or', label='MLE')\n",
    "plt.plot(range(1,Nflips+1), mu_MAP, '-*b', label='MAP')\n",
    "plt.plot(range(1,Nflips+1), [trueMU]*Nflips, '--g', label='True $\\mu$')\n",
    "plt.xlabel('Data points',size=15)\n",
    "plt.ylabel('MLE/MAP Estimations for $\\mu$',size=15)\n",
    "plt.legend(fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now see the effects on the posterior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True value of the unknown parameter\n",
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "\n",
    "# Prior Probability parameters\n",
    "a = 30; a_init = a\n",
    "b = 1;  b_init = b\n",
    "\n",
    "# Plotting data\n",
    "x = np.linspace(-0.1,1.1,100)\n",
    "xr = range(-1,3)\n",
    "\n",
    "# Prior probability, Beta(a,b)\n",
    "plt.plot(x, stats.beta(a,b).pdf(x))\n",
    "plt.xlabel('$\\mu$'); plt.ylabel('P($\\mu$)')\n",
    "plt.title('Initial Prior: alpha='+str(a)+', beta='+str(b),size=15)\n",
    "plt.show();\n",
    "\n",
    "print('Alpha = ', a)\n",
    "print('Beta = ', b)\n",
    "\n",
    "Nsamples = [1,2,5,10,50,100,150,200,500]\n",
    "Outcomes = stats.bernoulli(trueMU).rvs(size=Nsamples[-1])\n",
    "for i in range(len(Nsamples)):\n",
    "    Data = Outcomes[:Nsamples[i]]\n",
    "    \n",
    "    # Outcomes will have 1's or 0's (1 - Heads, 0 - Tails) \n",
    "    estimate_mu = (np.sum(Data)+a-1)/(len(Data)+a+b-2)\n",
    "    \n",
    "    # Data Likelihood:\n",
    "    fig=plt.figure(figsize=(15,5))\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.stem(xr, stats.bernoulli(np.sum(Data)/len(Data)).pmf(xr))\n",
    "    plt.xlabel('$x$'); plt.ylabel('P(X|$\\mu$)'); \n",
    "    plt.title('Data Likelihood, '+str(Nsamples[i])+' samples')\n",
    "    \n",
    "    # Posterior/Prior:\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.plot(x, stats.beta(a,b).pdf(x))\n",
    "    plt.xlabel('$\\mu$'); plt.ylabel('P($\\mu|$alpha, beta)'); \n",
    "    plt.title('Posterior/Prior: alpha='+str(a)+', beta='+str(b))\n",
    "    plt.show()\n",
    "    \n",
    "    # Update Prior distribution\n",
    "    a += np.sum(Data)\n",
    "    b += len(Data)-np.sum(Data)\n",
    "    \n",
    "    # Print estimate for mu\n",
    "    print('Number of samples: ', len(Data))\n",
    "    print('Data: ',Data)\n",
    "    print('MAP estimate mu = ', estimate_mu)\n",
    "    print('New alpha = ', a)\n",
    "    print('New beta = ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Conjugate Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many conjugate prior relationships, some examples include: \n",
    "1. Bernoulli-Beta,\n",
    "2. Gaussian-Gaussian, \n",
    "3. Gaussian-Inverse Wishart,\n",
    "4. Multinomial-Dirichlet,\n",
    "5. and others.\n",
    "\n",
    "The [table of conjugate distributions](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions) is very useful for selecting the prior probability in order to have a conjugate prior relationship for cases when the data likelihood is discrete (such as Bernoulli) or continuous (such as Gaussian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Could we update the prior as we receive data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What if we could fine-tune the prior probability's parameters ($\\alpha$ and $\\beta$, in this example) as we see more data?\n",
    "\n",
    "* Could we use the posterior probability to update the prior probability's parameters? That is, to select new values for $\\alpha$ and $\\beta$ using a data informative prior?\n",
    "\n",
    "* What cases would make this possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugate Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two distributions have a **conjugate prior** relationship when the form of the posterior is the same as the form of the prior.\n",
    "\n",
    "* Do the **Bernoulli-Beta** distributions have a conjugate prior relationship? Yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the posterior probability was defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\mu|\\mathbf{x}) &\\propto \\mu^{\\sum_{i=1}^N x_i+\\alpha-1} (1-\\mu)^{N-\\sum_{i=1}^N x_i+\\beta-1}\n",
    "\\end{align*}\n",
    "\n",
    "and, the prior probability (Beta distribution) is:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\mu|\\alpha, \\beta) &\\propto \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1}\n",
    "\\end{align*}\n",
    "\n",
    "(In both cases, the constant term was disregarded because it will not affect the solution for $\\mu$ during optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **posterior** and the **prior** probability have the same shape, hence they have a **<font color='blue'>conjugate prior</font>** relationship. Moreover, see that the parameters $\\alpha$ and $\\beta$ are now mapped to:\n",
    "\n",
    "\\begin{align*}\n",
    "\\alpha^{(t+1)} &\\leftarrow \\alpha^{(t)} + \\sum_{i=1}^N x_i\\\\\n",
    "\\beta^{(t+1)} &\\leftarrow \\beta^{(t)} + N - \\sum_{i=1}^N x_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an online model estimation scenario, where the posterior has the same form as the prior, we can use the posterior as our new prior. This new prior is now data informative and will update it's parameters based on (1) our initial choice, and (2) the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-Code for Online Update of the Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Iteration $t=0$\n",
    "2. Initialize the parameters of the prior probability, $\\alpha^{(t)}$ and $\\beta^{(t)}$\n",
    "3. As data comes in:\n",
    "    1. Compute the posterior probability, $\\mathcal{L}_{\\text{MAP}}^{(t)} = P(\\mathbf{x}|\\mu)P(\\mu|\\alpha^{(t)},\\beta^{(t)})$\n",
    "    2. Make an estimate for the parameter, $\\mu_{\\text{MAP}}^{(t)}$\n",
    "    3. Update parameters of prior probability:\n",
    "    \\begin{align*}\n",
    "    \\alpha^{(t+1)} &\\leftarrow \\alpha^{(t)} + \\sum_{i=1}^N x_i\\\\\n",
    "    \\beta^{(t+1)} &\\leftarrow \\beta^{(t)} + N - \\sum_{i=1}^N x_i\n",
    "    \\end{align*}\n",
    "    4. $t \\leftarrow t + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can implement this in code for this working example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True value of the unknown parameter\n",
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "\n",
    "# Prior Probability parameters\n",
    "a = 30; a_init = a\n",
    "b = 1;  b_init = b\n",
    "# Plotting prior\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "Beta = stats.beta(a_init,b_init)\n",
    "x = np.linspace(0,1,1000)\n",
    "plt.plot(x, Beta.pdf(x), label='Beta Distribution')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Probability of Heads\\n $\\mu$',fontsize=15)\n",
    "plt.ylabel('Prior Density Function\\n $P(\\mu)$',fontsize=15);\n",
    "\n",
    "# Sampling Training Data\n",
    "Nflips = 100\n",
    "Outcomes = stats.bernoulli(trueMU).rvs(Nflips)\n",
    "\n",
    "# Computing MLE and MAP estimates as data is being collected\n",
    "mu_MLE = []\n",
    "mu_MAP = []\n",
    "mu_MAP_update = []\n",
    "for i in range(1,Nflips+1):\n",
    "    mu_MLE += [np.sum(Outcomes[:i])/len(Outcomes[:i])]\n",
    "    mu_MAP += [(np.sum(Outcomes[:i])+a_init-1)/(len(Outcomes[:i])+a_init+b_init-2)]\n",
    "    mu_MAP_update += [(np.sum(Outcomes[:i])+a-1)/(len(Outcomes[:i])+a+b-2)]\n",
    "    a += np.sum(Outcomes[:i])\n",
    "    b += len(Outcomes[:i]) - np.sum(Outcomes[:i])\n",
    "\n",
    "# Plotting estimates\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1,Nflips+1), mu_MLE, '-or', label='MLE')\n",
    "plt.plot(range(1,Nflips+1), mu_MAP, '-*b', label='MAP (w/out online update)')\n",
    "plt.plot(range(1,Nflips+1), mu_MAP_update, '-^m', label='MAP (w/ online update)')\n",
    "plt.plot(range(1,Nflips+1), [trueMU]*Nflips, '--g', label='True $\\mu$')\n",
    "plt.xlabel('Data points',size=15)\n",
    "plt.ylabel('MLE/MAP Estimations for $\\mu$',size=15)\n",
    "plt.legend(fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now see the effects on the posterior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True value of the unknown parameter\n",
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "\n",
    "# Prior Probability parameters\n",
    "a = 30; a_init = a\n",
    "b = 1;  b_init = b\n",
    "\n",
    "# Plotting data\n",
    "x = np.linspace(-0.1,1.1,100)\n",
    "xr = range(-1,3)\n",
    "\n",
    "# Prior probability, Beta(a,b)\n",
    "plt.plot(x, stats.beta(a,b).pdf(x))\n",
    "plt.xlabel('$\\mu$'); plt.ylabel('P($\\mu$)')\n",
    "plt.title('Initial Prior: alpha='+str(a)+', beta='+str(b),size=15)\n",
    "plt.show();\n",
    "\n",
    "print('Alpha = ', a)\n",
    "print('Beta = ', b)\n",
    "\n",
    "Nsamples = [1,2,5,10,50,100,150,200,500]\n",
    "Outcomes = stats.bernoulli(trueMU).rvs(size=Nsamples[-1])\n",
    "for i in range(len(Nsamples)):\n",
    "    Data = Outcomes[:Nsamples[i]]\n",
    "    \n",
    "    # Outcomes will have 1's or 0's (1 - Heads, 0 - Tails) \n",
    "    estimate_mu = (np.sum(Data)+a-1)/(len(Data)+a+b-2)\n",
    "    \n",
    "    # Data Likelihood:\n",
    "    fig=plt.figure(figsize=(15,5))\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.stem(xr, stats.bernoulli(np.sum(Data)/len(Data)).pmf(xr))\n",
    "    plt.xlabel('$x$'); plt.ylabel('P(X|$\\mu$)'); \n",
    "    plt.title('Data Likelihood, '+str(Nsamples[i])+' samples')\n",
    "    \n",
    "    # Posterior/Prior:\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.plot(x, stats.beta(a,b).pdf(x))\n",
    "    plt.xlabel('$\\mu$'); plt.ylabel('P($\\mu|$alpha, beta)'); \n",
    "    plt.title('Posterior/Prior: alpha='+str(a)+', beta='+str(b))\n",
    "    plt.show()\n",
    "    \n",
    "    # Update Prior distribution\n",
    "    a += np.sum(Data)\n",
    "    b += len(Data)-np.sum(Data)\n",
    "    \n",
    "    # Print estimate for mu\n",
    "    print('Number of samples: ', len(Data))\n",
    "    print('Data: ',Data)\n",
    "    print('MAP estimate mu = ', estimate_mu)\n",
    "    print('New alpha = ', a)\n",
    "    print('New beta = ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Conjugate Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many conjugate prior relationships, some examples include: \n",
    "1. Bernoulli-Beta,\n",
    "2. Gaussian-Gaussian, \n",
    "3. Gaussian-Inverse Wishart,\n",
    "4. Multinomial-Dirichlet,\n",
    "5. and others.\n",
    "\n",
    "The [table of conjugate distributions](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions) is very useful for selecting the prior probability in order to have a conjugate prior relationship for cases when the data likelihood is discrete (such as Bernoulli) or continuous (such as Gaussian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:blue\">Maximum Likelihood Estimation (MLE)</span></h2>\n",
    "<center>(Frequentist approach)</center>\n",
    "\n",
    "$$\\arg_{\\mathbf{w}} \\max P(\\mathbf{t}|\\mathbf{w})$$\n",
    "\n",
    "In **Maximum Likelihood Estimation** we *find the set of parameters* that **maximize** the data likelihood $P(\\mathbf{t}|\\mathbf{w})$. We find the *optimal* set of parameters under some assumed distribution such that the data is most likely.\n",
    "\n",
    "* MLE focuses on maximizing the data likelihood, which *usually* provides a pretty good estimate\n",
    "\n",
    "* A common trick to maximize the data likelihood is to maximize the log likelihood\n",
    "\n",
    "* MLE is purely data driven \n",
    "\n",
    "* MLE works best when we have lots and lots of data\n",
    "\n",
    "* MLE will likely overfit when we have small amounts of data or, at least, becomes unreliable\n",
    "\n",
    "* It estimates relative frequency for our model parameters. Therefore it needs incredibly large amounts of data (infinite!) to estimate the true likelihood parameters\n",
    "    * This is a problem when we want to make inferences and/or predictions outside the range of what the training data has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:orange\">Maximum A Posteriori (MAP)</span></h2>\n",
    "<center>(Bayesian approach)</center>\n",
    "\n",
    "\\begin{align*}\n",
    "& \\arg_{\\mathbf{w}} \\max P(\\mathbf{t}|\\mathbf{w})P(\\mathbf{w}) \\\\ \n",
    "& \\propto \\arg_{\\mathbf{w}} \\max P(\\mathbf{w}|\\mathbf{t})\n",
    "\\end{align*}\n",
    "\n",
    "In **Maximum A Posteriori** we *find the set of parameters* that **maximize** the the posterior probability $P(\\mathbf{w}|\\mathbf{t})$. We find the *optimal* set of parameters under some assumed distribution such that the parameters are most likely to have been drawn off of.\n",
    "\n",
    "* MAP focuses on maximizing the posterior probability - data  likelihood with a prior\n",
    "\n",
    "* A common trick to maximize the posterior probability is to maximize the log likelihood\n",
    "\n",
    "* MAP is data driven \n",
    "\n",
    "* MAP is mostly driven by the prior beliefs\n",
    "\n",
    "* MAP works great with small amounts of data *if* our prior was chosen well\n",
    "\n",
    "* We need to assume and select a distribution for our prior beliefs\n",
    "    * A wrong choice of prior distribution can impact negatively our model estimation\n",
    "    \n",
    "* When we have lots and lots of data, the data likelihood will take over and the posterior will depend less and less on the prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
