{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 6 - Bayesian Interpretation, Maximum Likelihood Estimation (MLE) & Maximum A Posteriori (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Interpretation of the Least  Squares Estimator ($\\hat{\\mathbf{w}}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen some deﬁnitions of common estimators and analyzed their properties. But where did these estimators come from? Rather than guessing that some function might make a good estimator and then analyzing its bias and variance, we would like to have some principle from which we can derive specific functions that are good estimators for different models.\n",
    "\n",
    "Let's try to understand this better. Consider the objective function:\n",
    "\n",
    "\\begin{align*}\n",
    "J(\\mathbf{w}) &= \\frac{1}{2}\\sum_{i=1}^N \\left(t_i - y(\\phi(x_i),\\mathbf{w})\\right)^2\n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathbf{y}(\\phi(\\mathbf{x}),\\mathbf{w})$ is a model representation (e.g., linear regression), and $\\phi(x)$ is a feature mapping function (e.g. Gaussian Basis functions).\n",
    "\n",
    "The most common such principle is the **maximum likelihood** principle. Consider a set of $N$ examples $\\mathbf{x}=[x_1,x_2,\\dots,x_N]^T$ drawn independently from the true but unknown data-generating distribution $p_{\\text{data}}(x)$.\n",
    "\n",
    "Let $p_{\\text{model}}(\\phi(x);\\mathbf{w})$ be a parametric family of probability distributions over the same space indexed by $\\mathbf{w}$. In other words, $p_{\\text{model}}(\\phi(x);\\mathbf{w})$ maps any conﬁguration $\\phi(x)$ to a real number estimating the true probability $p_{\\text{data}}(\\phi(x))$.\n",
    "\n",
    "The maximum likelihood estimator for $\\mathbf{w}$ is then deﬁned as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{w}_{\\text{MLE}} &= \\arg_{\\mathbf{w}}\\max p_{\\text{model}}(\\phi(\\mathbf{x}); \\mathbf{w}) \\\\\n",
    "&= \\arg_{\\mathbf{w}}\\max \\prod_{i=1}^N p_{\\text{model}}(\\phi(x_i); \\mathbf{w}) \n",
    "\\end{align*}\n",
    "\n",
    "This product over many probabilities can be inconvenient for various reasons. For example, it is prone to numerical underﬂow. To obtain a more convenient but equivalent optimization problem, we observe that taking the logarithm of the likelihood does not change its arg max but does conveniently transform a product.\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{w}_{\\text{MLE}} &= \\arg_{\\mathbf{w}}\\max \\sum_{i=1}^N \\log p_{\\text{model}}(\\phi(x_i); \\mathbf{w}) \n",
    "\\end{align*}\n",
    "\n",
    "Because the arg max does not change when we rescale the cost function, we can divide by $N$ to obtain a version of the criterion that is expressed as an expectation with respect to the empirical distribution $p_{\\text{data}}$ deﬁned by the training data:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{w}_{\\text{MLE}} &= \\arg_{\\mathbf{w}}\\max \\mathbb{E}_{\\phi(x)\\sim \\hat{p}_{\\text{data}}} \\left[\\log p_{\\text{model}}(\\phi(x_i); \\mathbf{w})\\right]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Likelihood and the Least Squares Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum likelihood estimator can readily be generalized to estimate a conditional probability $P(\\mathbf{t}|\\phi(\\mathbf{x}); \\mathbf{w})$ in order to predict $t$ given $\\phi(x)$. This is actually the most common situation because it forms the basis for most supervised learning. If $\\mathbf{x}$ represents all our inputs and $\\mathbf{t} all our observed targets, then the conditional maximum likelihood estimator is\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{w}_{\\text{MLE}} &= \\arg_{\\mathbf{w}} \\max P(\\mathbf{t} | \\phi(\\mathbf{x}); \\mathbf{w})\n",
    "\\end{align*}\n",
    "\n",
    "If the examples are assumed to be i.i.d., then this can be decomposed into\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{w}_{\\text{MLE}} &= \\arg_{\\mathbf{w}} \\max \\sum_{i=1}^N \\log P(t_i | \\phi(x_i); \\mathbf{w})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares Solution of Linear Regression as the Maximum Likelihood Estimation (MLE) of $\\mathbf{w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with the least squares objective function may be justified as a maximum likelihood procedure. Previously, we motivated linear regression as an algorithm that learns to take a feature input $\\phi(x)$ and produce an output value $y$. The mapping from $\\phi(x)$ to $y$ is chosen to minimize the mean squared error, a criterion that we introduced more or less arbitrarily. \n",
    "\n",
    "We now revisit linear regression from the point of view of maximum likelihood estimation. Instead of producing a single prediction $y$, we now think of the model as producing a conditional distribution $p(\\mathbf{t}|\\phi(\\mathbf{x}))$. We can imagine that with an infinitely large training set, we might see several training examples with the same input value $\\phi(\\mathbf{x})$ but different values of $\\mathbf{t}$. The goal of the learning algorithm is now to fit the distribution $p(t|\\phi(x))$ to all those different $t$ values that are all compatible with $\\phi(x)$. To derive the same linear regression algorithm we obtained before, we define $p(t|\\phi(x)) = \\mathcal{N}\\left(t; f(\\phi(\\mathbf{x});\\mathbf{w}), \\sigma^2\\right)$. The function $f(\\phi(\\mathbf{x});\\mathbf{w})$ gives the prediction of the mean of the Gaussian. \n",
    "\n",
    "In this example, we assume that the variance is fixed to some constant $sigma^2$ chosen by the user. We will see that this choice of the functional form of $p(\\mathbf{t}|\\phi(\\mathbf{x}))$ causes the maximum likelihood estimation procedure to yield the same learning algorithm as we developed before. Since the examples are assumed to be i.i.d., the conditional log-likelihood is given by\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L} = \\log p(t_i | \\phi(x_i); \\mathbf{w}) &= -N\\log\\sigma -\\frac{N}{2}\\log(2\\pi)-\\sum_{i=1}^N\\frac{(t_i-y_i)^2}{2\\sigma^2}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can arrive at this same solution from a different perpective:\n",
    "\n",
    "\\begin{align*}\n",
    "\\arg_{\\mathbf{w}} \\min J(\\mathbf{w}) &= \\arg_{\\mathbf{w}} \\max - J(\\mathbf{w})\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max \\exp\\left(-J(\\mathbf{w})\\right)\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^N \\left(t_i - y_i\\right)^2\\right)\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max \\prod_{i=1}^N\\exp\\left(-\\frac{1}{2} \\left(t_i - y_i\\right)^2\\right)\\\\\n",
    "&\\propto \\arg_{\\mathbf{w}} \\max \\prod_{i=1}^N \\mathcal{N}\\left(t_i;y_i,1\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the univariate Gaussian pdf is defined as: $\\mathcal{N}(x; \\mu, \\sigma^2) \\sim \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying our \"trick\", the natural logarithm:\n",
    "\n",
    "\\begin{align*}\n",
    "\\arg_{\\mathbf{w}} \\max & \\prod_{i=1}^N \\mathcal{N}\\left(t_i;y_i,1\\right)\\\\\n",
    "\\propto & \\arg_{\\mathbf{w}} \\max \\ln \\prod_{i=1}^N \\mathcal{N}\\left(t_i;y_i,1\\right)\\\\\n",
    "= & \\arg_{\\mathbf{w}} \\max \\sum_{i=1}^N \\ln \\mathcal{N}\\left(t_i;y_i,1\\right)\n",
    "\\end{align*}\n",
    "\n",
    "We can expand the last term as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_{i=1}^N \\ln \\mathcal{N}\\left(t_i;y_i,1\\right) &= \\sum_{i=1}^N \\ln \\left( \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{-\\frac{1}{2} (t_i-y_i)^2 \\right\\} \\right)\\\\\n",
    "&= \\sum_{i=1}^N -\\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2}(t_i-y_i)^2\\\\\n",
    "&= -\\frac{N}{2} -\\sum_{i=1}^N \\frac{1}{2}(t_i-y_i)^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step to find the arg $\\mathbf{w}$ that maximizes this log-likelihood is to take the derivative of this function with respect to (w.r.t.) $\\mathbf{w}$, set it to 0 and solve for $\\mathbf{w}$.\n",
    "\n",
    "If we consider the special case of a linear regression model, we have: $y_i = \\sum_{j=0}^M w_jx_i^j = \\mathbf{w}^T\\phi(x_i)$, where $\\phi(x)$ is the polynomial basis function. Hence:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L} &= -\\frac{N}{2} -\\sum_{i=1}^N \\frac{1}{2}(t_i-\\mathbf{w}^T\\phi(x_i))^2\\\\\n",
    "&= -\\frac{N}{2} - \\frac{1}{2} \\Vert \\mathbf{t} - \\mathbf{X}\\mathbf{w}\\Vert^2_2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, if we take the derivative\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial\\mathcal{L}}{\\partial\\mathbf{w}}=0\n",
    "\\end{align*}\n",
    "\n",
    "We will arrive at the same solution:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{w}_{\\text{MLE}} &= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression as Maximum A Posteriori (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How can we interpret the optimization problem when we consider a regularization term (ridge or lasso) in the objective function?**\n",
    "\n",
    "Consider \n",
    "\n",
    "\\begin{align*}\n",
    "J(\\mathbf{w}) = \\frac{1}{2}\\sum_{i=1}^N (t_i - y_i)^2 + \\frac{\\lambda}{2}\\sum_{j=0}^M w_j^2\n",
    "\\end{align*}\n",
    "\n",
    "As before, we have \n",
    "\n",
    "\\begin{align*}\n",
    "\\arg_{\\mathbf{w}} \\min J(\\mathbf{w}) &= \\arg_{\\mathbf{w}} \\max - J(\\mathbf{w})\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max \\exp\\left(-J(\\mathbf{w})\\right)\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^N \\left(t_i - y_i\\right)^2 - \\frac{\\lambda}{2} \\sum_{j=0}^M w_j^2\\right)\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max \\prod_{i=1}^N\\exp\\left(-\\frac{1}{2} \\left(t_i - y_i\\right)^2\\right)\\prod_{j=0}^M\\exp\\left(-\\frac{\\lambda}{2} w_j^2\\right)\\\\\n",
    "&\\propto \\arg_{\\mathbf{w}} \\max \\prod_{i=1}^N \\mathcal{N}\\left(t_i;y_i,1\\right)\\prod_{j=0}^M \\mathcal{N}\\left(w_j;0, \\frac{1}{\\lambda}\\right)\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max p(\\mathbf{t}| \\mathbf{y}(\\mathbf{x};\\mathbf{w})) p(\\mathbf{w}| \\lambda)\\\\\n",
    "&\\propto \\arg_{\\mathbf{w}} \\max p(\\mathbf{w}| \\mathbf{t})\n",
    "\\end{align*}\n",
    "\n",
    "We see that adding a regularization penalty term to the objective function is equivalent to adding a prior probability on the parameters. \n",
    "\n",
    "For the ridge penalty, the probabilistic model of the prior probability is a Gaussian distribution with mean 0 and variance $1/\\lambda$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression as Maximum A Posteriori (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider \n",
    "\n",
    "\\begin{align*}\n",
    "J(\\mathbf{x};\\mathbf{w}) = \\frac{1}{2}\\sum_{i=1}^N (t_i - y_i)^2 + \\frac{\\lambda}{2}\\sum_{j=0}^M |w_j|\n",
    "\\end{align*}\n",
    "\n",
    "As before, we have \n",
    "\n",
    "\\begin{align*}\n",
    "\\arg_{\\mathbf{w}} \\min J(\\mathbf{w}) &= \\arg_{\\mathbf{w}} \\max - J(\\mathbf{w})\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max \\exp\\left(-J(\\mathbf{w})\\right)\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^N \\left(t_i - y_i\\right)^2 - \\frac{\\lambda}{2} \\sum_{j=0}^M |w_j|\\right)\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max \\prod_{i=1}^N\\exp\\left(-\\frac{1}{2} \\left(t_i - y_i\\right)^2\\right)\\prod_{j=0}^M\\exp\\left(-\\frac{\\lambda}{2} |w_j|\\right)\\\\\n",
    "&\\propto \\arg_{\\mathbf{w}} \\max \\prod_{i=1}^N \\mathcal{N}\\left(t_i;y_i,1\\right)\\prod_{j=0}^M \\mathcal{L}\\text{aplacian}\\left(w_j;0, \\frac{1}{\\lambda}\\right)\\\\\n",
    "&= \\arg_{\\mathbf{w}} \\max p(\\mathbf{t}| \\mathbf{y}(\\mathbf{x};\\mathbf{w})) p(\\mathbf{w}| \\lambda)\\\\\n",
    "&\\propto \\arg_{\\mathbf{w}} \\max p(\\mathbf{w}| \\mathbf{t})\n",
    "\\end{align*} \n",
    "\n",
    "For the lasso penalty, the probabilistic model of the prior probability is a Laplacian distribution with parameters $\\mu=0$ and $b = 1/\\lambda$. \n",
    "\n",
    "Recall that the Laplacian pdf has two parameters, $\\mu$ and $b$ ($b>0$), and its function is defined as: $\\mathcal{L}\\text{aplacian}(\\mu, b) \\sim \\frac{1}{2b}\\exp\\left\\{-\\frac{|x-\\mu|}{b}\\right\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10,10,1000)\n",
    "\n",
    "lam = 0.1\n",
    "\n",
    "G = stats.norm(0, np.sqrt(1/lam))\n",
    "L = stats.laplace(0, np.sqrt(1/lam))\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, G.pdf(x), '--', label='Ridge: $\\mathcal{N}(\\mu=0,\\sigma^2=1/\\lambda)$')\n",
    "plt.plot(x, L.pdf(x), label='Lasso: $\\mathcal{L}(\\mu=0,b=1/\\lambda)$')\n",
    "plt.legend(loc='best', fontsize=15); plt.xlabel('$\\mathbf{w}$', size=15)\n",
    "plt.ylabel('$P(\\mathbf{w})$', size=15); plt.title('Prior Probability',size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation (MLE) & Maximum A Posteriori (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:blue\">Maximum Likelihood Estimation (MLE)</span></h2>\n",
    "<center>(Frequentist approach)</center>\n",
    "\n",
    "In **Maximum Likelihood Estimation** (also referred to as **MLE**) we want to *find the set of parameters* that **maximize** the data likelihood $P(\\mathbf{t}|\\mathbf{y}(\\mathbf{x};\\mathbf{w}))$. We want to find the *optimal* set of parameters under some assumed distribution such that the data is most likely.\n",
    "\n",
    "* MLE focuses on maximizing the data likelihood, which *usually* provides a pretty good estimate\n",
    "\n",
    "* A common trick to maximize the data likelihood is to maximize the log likelihood\n",
    "\n",
    "* MLE is purely data driven \n",
    "\n",
    "* MLE works best when we have lots and lots of data\n",
    "\n",
    "* MLE will likely overfit when we have small amounts of data or, at least, becomes unreliable\n",
    "\n",
    "* It estimates relative frequency for our model parameters. Therefore it needs incredibly large amounts of data (infinite!) to estimate the true likelihood parameters\n",
    "    * This is a problem when we want to make inferences and/or predictions outside the range of what the training data has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:orange\">Maximum A Posteriori (MAP)</span></h2>\n",
    "<center>(Bayesian approach)</center>\n",
    "\n",
    "In **Maximum A Posteriori** (also referred as **MAP**) we want to *find the set of parameters* that **maximize** the posterior probability $P(\\mathbf{w}|\\mathbf{t})$. We want to find the *optimal* set of parameters under some assumed distribution such that the parameters are most likely to have been drawn off of given some prior beliefs.\n",
    "\n",
    "* MAP focuses on maximizing the posterior probability - data  likelihood with a prior\n",
    "\n",
    "* A common trick to maximize the posterior probability is to maximize the log likelihood\n",
    "\n",
    "* MAP is data driven \n",
    "\n",
    "* MAP is mostly driven by the prior beliefs\n",
    "\n",
    "* MAP works great with small amounts of data *if* our prior was chosen well\n",
    "\n",
    "* We need to assume and select a distribution for our prior beliefs\n",
    "    * A wrong choice of prior distribution can impact negatively our model estimation\n",
    "    \n",
    "* When we have lots and lots of data, the data likelihood will take over and the posterior will depend less and less on the prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppose you flip a coin 3 times. Let $H_i$ be the event that we observe Heads on flip $i$. Consider the event $E=H_1\\cap H_2\\cap H_3$, i.e. all flips were Heads. What is the probability that the next flip is Heads?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From classical probability (frequentist), we look only at data to compute the probability of flipping Heads:\n",
    "\n",
    "\\begin{align*}\n",
    "P(H) = \\frac{\\text{No. of observed Heads}}{\\text{No. of flips}} = \\frac{3}{3} = 1\n",
    "\\end{align*}\n",
    "\n",
    "From Bayesian statistics, we use Bayesian inferencing: What is the **hidden state** in this problem?\n",
    "\n",
    "* Hidden state: what type of coin was use in the experiment\n",
    "* Let's assume that we think only two types of coins could have been used, one fair coin and one 2-headed coin. So, by the **Law of Total Probability**:\n",
    "\n",
    "\\begin{align*}\n",
    "P(H) = P(H|\\text{fair})P(\\text{fair}) + P(\\overline{H}|\\text{2-headed})P(\\text{2-headed})\n",
    "\\end{align*}\n",
    "\n",
    "Furthermore, we can test different hypothesis by checking which hypothesis has the largest posterior probability value, e.g. if $P(\\text{fair}|E) > P(\\text{2-headed}|E)$, then hypothesis \"fair\" is more likely and that is what we will use to make predictions.\n",
    "    \n",
    "Note that the events $H_i$ are **conditionally independent**, that is: $P(H_1\\cap H_2|\\text{fair}) = P(H_1|\\text{fair})P(H_2|\\text{fair})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE and MAP Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign heads to the numerical value 1 and tails to 0. The sample space is $S=\\{0,1\\}$. Let $X$ be the discrete random variable (R.V.) that describes the outcome of flipping a coin. Furthermore, let the probability of heads ($x=1$) be equal to some *unknown* value $\\mu$. The probability mass function (pmf) of this R.V. is defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "p(x|\\mu) = \\begin{cases} \\mu & \\text{if } x=1 \\\\ 1-\\mu & \\text{if }x=0\\\\ 0 & \\text{otherwise}  \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "* This is the **Bernoulli** discrete R.V.. The mean and variance (1st and 2nd moment) of the Bernoulli distribution are: $E[x] = \\mu$ and $E[\\left(x- E[x]\\right)^2] = \\mu(1-\\mu)$.\n",
    "\n",
    "* So, for every outcome of the event $E$, we will model it using a Bernoulli distribution, and each outcome is pairwise **conditionally independent**. Therefore, we have the event $E$ contains i.i.d. outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood (MLE) Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity of calculation, let $E=x_1\\cap x_2\\cap \\dots\\cap x_N$, where $x_i=\\{0,1\\}$ (0 for Tails and 1 for Heads). Then, for an experiment with $N$ samples, we can write the **data likelihood** as:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\mathbf{x}|\\mu) &= P(x_1\\cap x_2\\cap \\dots\\cap x_N|\\mu) \\\\\n",
    "&= P(x_1|\\mu)P(x_2|\\mu)\\dots P(x_N|\\mu) \\\\\n",
    "&= \\prod_{n=1}^N p(x_n|\\mu) \\\\\n",
    "&= \\prod_{n=1}^N \\mu^{x_n} (1-\\mu)^{1-x_n}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are interested in finding the value of $\\mu$ given a set of samples $\\mathbf{x}=\\{x_i\\}_{i=1}^N$. \n",
    "\n",
    "To optimize the data likelihood, we can apply the natural logarithm function to simplify:\n",
    "\n",
    "\\begin{align*}\n",
    "arg_\\mathbf{\\mu} \\max P(\\mathbf{x}|\\mu) &= \\arg_\\mathbf{\\mu} \\max \\ln \\left( P(\\mathbf{x}|\\mu) \\right)\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L} &= \\ln \\left( P(\\mathbf{x}|\\mu) \\right) = \\sum_{n=1}^N \\left(x_n \\ln(\\mu) + (1-x_n)\\ln(1-\\mu)\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can take the derivative of this function with respect to (w.r.t.) $\\mu$ and equal it to zero:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mu} &= 0\\\\\n",
    "(1-\\mu)\\sum_{n=1}^N x_n - \\mu \\left(N - \\sum_{n=1}^N x_n\\right) &= 0 \\\\\n",
    "\\sum_{n=1}^N x_n - \\mu\\sum_{n=1}^N x_n - \\mu N + \\mu\\sum_{n=1}^N x_n &= 0 \\\\\n",
    "\\sum_{n=1}^N x_n - \\mu N &= 0 \\\\\n",
    "\\mu_{\\text{MLE}} &= \\frac{1}{N} \\sum_{n=1}^N x_n\n",
    "\\end{align*}\n",
    "\n",
    "As expected, the MLE estimation for the probability of seeing heads in the next coin flip is equal to the **relative frequency** of the outcome heads.\n",
    "\n",
    "* Suppose you flipped the coin only once, and saw Tails. The probability of flipping Heads according to MLE would be 0.\n",
    "\n",
    "* MLE is **purely data driven**! This is sufficient *when* we have lots and lots of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum A Posteriori (MAP) Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MAP estimation of $\\mu$, we are instead optimizing the posterior probability:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\arg_{\\mu} \\max P(\\mu|\\mathbf{x}) \\\\\n",
    "=& \\arg_{\\mu} \\max \\frac{P(\\mathbf{x}|\\mu) P(\\mu)}{P(\\mathbf{x})} \\\\\n",
    "\\propto & \\text{  } \\arg_{\\mu} \\max P(\\mathbf{x}|\\mu) P(\\mu), P(\\mathbf{x})\\text{ is some constant value} \n",
    "\\end{align*}\n",
    "\n",
    "We have defined the data likelihood $P(\\mathbf{x}|\\mu)$, we now need to choose a **prior distribution** $P(\\mu)$.\n",
    "\n",
    "* This prior distribution will *encode* any prior knowledge we have about the hidden sate of the problem, in this case, the type of coin that was used.\n",
    "\n",
    "Let's say our **prior distribution** is the Beta Distribution. The Beta Distribution takes the form:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Beta}(x|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}\n",
    "\\end{align*}\n",
    "\n",
    "where $\\Gamma(x) = (x-1)!$ and $\\alpha,\\beta>0$.\n",
    "\n",
    "The mean and variance of the Beta distribution are: $E[x] = \\frac{\\alpha}{\\alpha+\\beta}$ and $E[(x-E[x])^2] = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's see what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "b = 20\n",
    "x = np.arange(0,1,0.0001)\n",
    "Beta = (math.gamma(a+b)/(math.gamma(a)*math.gamma(b)))*x**(a-1)*(1-x)**(b-1)\n",
    "\n",
    "plt.plot(x, Beta, label='Beta Distribution')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Probability of Heads\\n $\\mu$',fontsize=15)\n",
    "plt.ylabel('Prior Probability\\n $P(\\mu)$',fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Beta Distribution as out prior, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\mu|\\alpha,\\beta) &= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&\\propto \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let:\n",
    "* $m$ the number of heads\n",
    "* $l$ the number of tails\n",
    "* $N=m+l$ the total number of coin flips \n",
    "\n",
    "We can write our **posterior probability** as:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\mu|\\mathbf{x}) &= \\frac{P(\\mathbf{x}|\\mu)P(\\mu)}{P(\\mathbf{x})}\\\\\n",
    "&\\propto P(\\mathbf{x}|\\mu)P(\\mu)\\\\\n",
    "&= \\left(\\prod_{n=1}^N \\mu^{x_n} (1-\\mu)^{1-x_n}\\right) \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&= \\mu^m (1-\\mu)^l \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&= \\mu^{m+\\alpha-1} (1-\\mu)^{l+\\beta-1}\n",
    "\\end{align*}\n",
    "\n",
    "The posterior probability has the same shape as the data likelihood. \n",
    "\n",
    "This is a special case called **Conjugate Prior Relationship**, which happens when the posterior has the same form as the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now optimize our posterior probability, and we will apply the same trick:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L} &= \\ln P(\\mu|\\mathbf{x}) = (m+\\alpha-1)\\ln(\\mu) + (l+\\beta-1)\\ln(1-\\mu)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now *optimize* our posterior probability:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mu} = 0 \\iff & \\frac{m+\\alpha-1}{\\mu} + \\frac{l+\\beta-1}{1-\\mu} = 0\\\\\n",
    "\\mu_{\\text{MAP}} &= \\frac{m+\\alpha-1}{m + l + \\alpha + \\beta -2}\n",
    "\\end{align*}\n",
    "\n",
    "This is our estimation of the probability of heads using MAP!\n",
    "\n",
    "* Our estimation for the probability of heads, $\\mu$, is going to depend on $\\alpha$ and $\\beta$ introduced by the prior distribution. We saw that they control the level of certainty as well as the center value.\n",
    "\n",
    "* With only a few samples, the prior will play a bigger role in the decision, but eventually the data takes over the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate this example with code:\n",
    "\n",
    "We saw the example where our input dataset $\\{x_i\\}_{i=1}^N$ is binary, where $x_i=\\{0,1\\}, \\forall i$. \n",
    "\n",
    "For each data sample $x_i$, we modeled its data likelihood as the Bernoulli distribution with parameter $\\mu$, i.e.\n",
    "\n",
    "\\begin{align*}\n",
    "x_i \\sim \\text{Bernoulli}(\\mu)\n",
    "\\end{align*}\n",
    "\n",
    "Furthermore, we assume that each sample is independent of each other. Hence our dataset is a collection of i.i.d. samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "## Prior Probability\n",
    "a = 2\n",
    "b = 20\n",
    "Beta = stats.beta(a,b)\n",
    "x = np.linspace(0,1,1000)\n",
    "\n",
    "plt.plot(x, Beta.pdf(x), label='Beta Distribution')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Probability of Heads\\n $\\mu$',fontsize=15)\n",
    "plt.ylabel('Prior Density Function\\n $P(\\mu)$',fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "\n",
    "Nflips = 10\n",
    "\n",
    "Outcomes = []\n",
    "for i in range(Nflips):\n",
    "    Outcomes += [stats.bernoulli(trueMU).rvs(1)[0]]\n",
    "    print(Outcomes)\n",
    "    print('MLE (Frequentist, data-driven): Probability of Heads = ', np.sum(Outcomes)/len(Outcomes))\n",
    "    print('MAP (Bayesian, uses prior): Probability of Heads = ', (np.sum(Outcomes)+a-1)/(len(Outcomes)+a+b-2))\n",
    "    input('Press enter to flip the coin again...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True value of the unknown parameter\n",
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "\n",
    "# Prior Initial Parameters\n",
    "a=2 # alpha\n",
    "b=20 # beta\n",
    "# Plotting prior\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "Beta = stats.beta(a,b)\n",
    "x = np.linspace(0,1,1000)\n",
    "plt.plot(x, Beta.pdf(x), label='Beta Distribution')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Probability of Heads\\n $\\mu$',fontsize=15)\n",
    "plt.ylabel('Prior Density Function\\n $P(\\mu)$',fontsize=15);\n",
    "\n",
    "\n",
    "# Sampling Training Data\n",
    "Nflips = 100\n",
    "Outcomes = stats.bernoulli(trueMU).rvs(Nflips)\n",
    "\n",
    "# Computing MLE and MAP estimates as data is being collected\n",
    "mu_MLE = []\n",
    "mu_MAP = []\n",
    "for i in range(1,Nflips+1):\n",
    "    mu_MLE += [np.sum(Outcomes[:i])/len(Outcomes[:i])]\n",
    "    mu_MAP += [(np.sum(Outcomes[:i])+a-1)/(len(Outcomes[:i])+a+b-2)]\n",
    "\n",
    "# Plotting estimates\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1,Nflips+1), mu_MLE, '-or', label='MLE')\n",
    "plt.plot(range(1,Nflips+1), mu_MAP, '-*b', label='MAP')\n",
    "plt.plot(range(1,Nflips+1), [trueMU]*Nflips, '--g', label='True $\\mu$')\n",
    "plt.xlabel('Data points',size=15)\n",
    "plt.ylabel('MLE/MAP Estimations for $\\mu$',size=15)\n",
    "plt.legend(fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now see the effects on the posterior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True value of the unknown parameter\n",
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "\n",
    "# Prior Probability parameters\n",
    "a = 30; a_init = a\n",
    "b = 1;  b_init = b\n",
    "\n",
    "# Plotting data\n",
    "x = np.linspace(-0.1,1.1,100)\n",
    "xr = range(-1,3)\n",
    "\n",
    "# Prior probability, Beta(a,b)\n",
    "plt.plot(x, stats.beta(a,b).pdf(x))\n",
    "plt.xlabel('$\\mu$'); plt.ylabel('P($\\mu$)')\n",
    "plt.title('Initial Prior: alpha='+str(a)+', beta='+str(b),size=15)\n",
    "plt.show();\n",
    "\n",
    "print('Alpha = ', a)\n",
    "print('Beta = ', b)\n",
    "\n",
    "Nsamples = [1,2,5,10,50,100,150,200,500]\n",
    "Outcomes = stats.bernoulli(trueMU).rvs(size=Nsamples[-1])\n",
    "for i in range(len(Nsamples)):\n",
    "    Data = Outcomes[:Nsamples[i]]\n",
    "    \n",
    "    # Outcomes will have 1's or 0's (1 - Heads, 0 - Tails) \n",
    "    estimate_mu = (np.sum(Data)+a-1)/(len(Data)+a+b-2)\n",
    "    \n",
    "    # Data Likelihood:\n",
    "    fig=plt.figure(figsize=(15,5))\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.stem(xr, stats.bernoulli(np.sum(Data)/len(Data)).pmf(xr))\n",
    "    plt.xlabel('$x$'); plt.ylabel('P(X|$\\mu$)'); \n",
    "    plt.title('Data Likelihood, '+str(Nsamples[i])+' samples')\n",
    "    \n",
    "    # Posterior/Prior:\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.plot(x, stats.beta(a,b).pdf(x))\n",
    "    plt.xlabel('$\\mu$'); plt.ylabel('P($\\mu|$alpha, beta)'); \n",
    "    plt.title('Posterior/Prior: alpha='+str(a)+', beta='+str(b))\n",
    "    plt.show()\n",
    "    \n",
    "    # Update Prior distribution\n",
    "    a += np.sum(Data)\n",
    "    b += len(Data)-np.sum(Data)\n",
    "    \n",
    "    # Print estimate for mu\n",
    "    print('Number of samples: ', len(Data))\n",
    "    print('Data: ',Data)\n",
    "    print('MAP estimate mu = ', estimate_mu)\n",
    "    print('New alpha = ', a)\n",
    "    print('New beta = ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Conjugate Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many conjugate prior relationships, some examples include: \n",
    "1. Bernoulli-Beta,\n",
    "2. Gaussian-Gaussian, \n",
    "3. Gaussian-Inverse Wishart,\n",
    "4. Multinomial-Dirichlet,\n",
    "5. and others.\n",
    "\n",
    "The [table of conjugate distributions](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions) is very useful for selecting the prior probability in order to have a conjugate prior relationship for cases when the data likelihood is discrete (such as Bernoulli) or continuous (such as Gaussian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Could we update the prior as we receive data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What if we could fine-tune the prior probability's parameters ($\\alpha$ and $\\beta$, in this example) as we see more data?\n",
    "\n",
    "* Could we use the posterior probability to update the prior probability's parameters? That is, to select new values for $\\alpha$ and $\\beta$ using a data informative prior?\n",
    "\n",
    "* What cases would make this possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
